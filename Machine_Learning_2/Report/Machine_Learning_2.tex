\documentclass[DIV=calc, paper=a4, fontsize=11pt, twocolumn]{scrartcl}	 % A4 paper and 11pt font size

\usepackage{multirow}
\usepackage{graphicx}
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template
\usepackage[english]{babel} % English language/hyphenation
\usepackage[protrusion=true,expansion=true]{microtype} % Better typography
\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage[svgnames]{xcolor} % Enabling colors by their 'svgnames'
\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} % Custom captions under/above floats in tables or figures
\usepackage{booktabs} % Horizontal rules in tables
\usepackage{fix-cm}	 % Custom font sizes - used for the initial letter in the document

\usepackage{sectsty} % Enables custom section titles
\allsectionsfont{\usefont{OT1}{phv}{b}{n}} % Change the font of all section commands

\usepackage{fancyhdr} % Needed to define custom headers/footers
\pagestyle{fancy} % Enables the custom headers/footers
\usepackage{lastpage} % Used to determine the number of pages in the document (for "Page X of Total")

% Headers - all currently empty
\lhead{}
\chead{}
\rhead{}

% Footers
\lfoot{}
\cfoot{}
\rfoot{\footnotesize Page \thepage\ of \pageref{LastPage}} % "Page 1 of 2"

\renewcommand{\headrulewidth}{0.0pt} % No header rule
\renewcommand{\footrulewidth}{0.4pt} % Thin footer rule

\usepackage{lettrine} % Package to accentuate the first letter of the text
\newcommand{\initial}[1]{ % Defines the command and style for the first letter
\lettrine[lines=3,lhang=0.3,nindent=0em]{
\color{DarkGoldenrod}
{\textsf{#1}}}{}}

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\usepackage{titling} % Allows custom title configuration

\newcommand{\HorRule}{\color{DarkGoldenrod} \rule{\linewidth}{1pt}} % Defines the gold horizontal rule around the title

\pretitle{\vspace{-30pt} \begin{flushleft} \HorRule \fontsize{20}{20} \usefont{OT1}{phv}{b}{n} \color{DarkRed} \selectfont} % Horizontal rule before the title

\title{Machine Learning (Problem set 2)} % Your article title

\posttitle{\par\end{flushleft}\vskip 0.5em} % Whitespace under the title

\preauthor{\begin{flushleft}\large \lineskip 0.5em \usefont{OT1}{phv}{b}{sl} \color{DarkRed}} % Author font configuration

\author{Ali Alipour, } % Your name

\postauthor{\footnotesize \usefont{OT1}{phv}{m}{sl} \color{Black} % Configuration for the institution name
University of Tehran % Your institution

\par\end{flushleft}\HorRule} % Horizontal rule after the title

\date{} % Add a date here if you would like one to appear underneath the title block

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title

\thispagestyle{fancy} % Enabling the custom headers/footers for the first page 

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

% The first character should be within \initial{}
\initial{T}\textbf{his report explores the implementation of various machine learning techniques. 
                   In Question 1, we analyze the performance of linear models under noise by calculating MSE, 
                   bias, and variance. Question 2 involves classifying random data points using logistic regression 
                   and feature mapping. In Question 3, we implement Parzen window estimation for kernel density estimation. 
                   These exercises provide insights into the trade-offs between model complexity, bias, and variance.}
%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\section*{\small{Question 1}}

\begin{enumerate}
    \item First, we define the functions and libraries as required.
    \item Next, we generate the required dataset by applying Poisson and normal distributions and introducing noise to the data. After applying the noise, we define a function that creates a linear model with varying degrees. Then, we calculate the Mean Squared Error (MSE) for each model and record the errors.
    \item After obtaining the models, we plot the data and the corresponding models.
    \item Then, we calculate the bias and variance for the models using the \texttt{bias\_variance\_decomp} function and display the results. We observe that as the model complexity increases, bias decreases and variance increases.
\end{enumerate}

\section*{\small{Question 2}}

\begin{enumerate}
    \item First, we define the necessary functions and libraries. We generate random data points within a specified radius and display the corresponding images.
    \item Next, we repeat the process for a second scenario, generating and displaying the random data points again.
    \item Using the generated data, we organize them into a DataFrame and assign labels to them.
    \item We then write a manual code to split the data into training and testing sets.
    \item Using the Logistic Regression class, we manually implement a logistic regression algorithm to classify the data.
    \item Afterward, we increase the features using a mapping function to enhance the classification process.
    \item Finally, we implement a classification algorithm using radial data generated from uniform and normal distributions and report the results.
\end{enumerate}

\section*{\small{Question 3}}

In this example, we aim to implement the Parzen algorithm.

\begin{enumerate}
    \item First, we load the dataset. We define both the Gaussian kernel and the estimated kernel function.
    \item We extract the "duration" column from the dataset and represent it as a list. We proceed to plot the results of the kernel density estimations for different values of "duration."
    \item We use the \texttt{kernelDensity} function to compute the kernel density and plot the results.
    \item Lastly, we perform Parzen window estimation for a subset of 250 data points and visualize the results.
\end{enumerate}

%----------------------------------------------------------------------------------------
%	REFERENCE LIST
%----------------------------------------------------------------------------------------

\begin{thebibliography}{99} % Bibliography - this is intentionally simple in this template

  \bibitem[Alipour Fraydani, 2024]{AlipourFraydani:2024}
  Alipour Fraydani, A. (2024).
  \newblock Homework on Machine Learning problem set 2, University of Tehran.
  \newblock {\em Unpublished Manuscript}, Department of Electrical Engineering, University of Tehran.
  
\end{thebibliography}

%----------------------------------------------------------------------------------------

\end{document}